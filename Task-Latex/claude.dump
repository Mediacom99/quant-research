Your approach of using traditional PCA on factors followed by regression for forecasting expected returns is a well-established method in finance. While it may be considered "traditional," it's not necessarily naive or outdated. In fact, it's often used as a baseline or benchmark for more complex models. That said, there are some considerations and tests you should perform to ensure the approach is suitable for your data.
Let's break this down:

Approach Overview:

PCA on factors to reduce dimensionality and extract principal components
Regression (OLS or GLS) to forecast expected returns using these components


Suitability of the Approach:
This method can be effective, especially for capturing linear relationships between stock returns and factors. However, it has limitations:

It assumes linear relationships, which may not always hold in financial markets
It doesn't capture non-linear or complex interactions between factors
It may not account for time-varying relationships or regime changes


Tests and Checks:

Before applying this approach, you should conduct several tests on your data:
a) Stationarity Tests:

Augmented Dickey-Fuller (ADF) test
KPSS test
Ensure your time series are stationary or properly differenced

b) Correlation Analysis:

Check for multicollinearity among factors
Correlation matrix and VIF (Variance Inflation Factor) analysis

c) Normality Tests:

Shapiro-Wilk test
Q-Q plots
Jarque-Bera test

d) Heteroscedasticity Tests:

White's test
Breusch-Pagan test

e) Autocorrelation Tests:

Durbin-Watson test
ACF and PACF plots

f) Linearity Checks:

Scatter plots
Residual plots

g) Structural Breaks:

Chow test
CUSUM test

h) Cointegration Tests (if using levels data):

Johansen test
Engle-Granger test


Model Validation:

Use cross-validation techniques (e.g., rolling window or expanding window)
Compare against simple benchmarks (e.g., historical mean, random walk)
Evaluate out-of-sample performance


Potential Enhancements:

Consider time-varying parameters (e.g., rolling window regressions)
Explore non-linear models (e.g., neural networks, random forests) for comparison
Incorporate regime-switching models to capture market states

DATA ANALYSIS: 

Regression Choice:

OLS is a good starting point
GLS might be more appropriate if you detect heteroscedasticity or autocorrelation
Consider robust regression methods if you have outliers


Factor Selection:

Ensure your factors are economically meaningful
Consider using established factor models (e.g., Fama-French) as a baseline


Interpretability:

One advantage of your approach is its interpretability, which can be valuable for understanding factor contributions



While this approach may not be the most cutting-edge, it has the advantages of being interpretable, computationally efficient, and well-understood. It can serve as a solid baseline and provide insights into factor relationships.
For a more advanced approach, you might consider:

Dynamic factor models
Machine learning methods (e.g., elastic net, random forests)
Time series models that account for GARCH effects

Remember, the best model often depends on your specific data, forecasting horizon, and the balance between complexity and interpretability that you're aiming for.